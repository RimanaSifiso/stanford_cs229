{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8905e80-6820-47b6-b425-a7883f88ec84",
   "metadata": {},
   "source": [
    "# Practical 1: PyTorch basics I\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffc5f950-3d24-4c6c-9957-472b43ef2fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344a074f-c708-40b4-ad72-e00ab0517776",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 0. Introduction\n",
    "\n",
    "In this practical lab, we discuss the basics of PyTorch, a Python library for machine learning and deep learning. Specifically, we cover\n",
    "- Tensors and their initialisation\n",
    "- Tensor math\n",
    "- Tensor indexing\n",
    "- Tensor reshaping\n",
    "- The three common mistakes (or errors) in PyTorch \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b3930-b7f3-47e4-b851-41fa146543b6",
   "metadata": {},
   "source": [
    "## 1. Tensor Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d16db-586f-458d-901d-69e495d755b2",
   "metadata": {},
   "source": [
    "PyTorch tensors can represent scalars (or numbers), vectors (list of numbers), matrices (grid of numbers), and $n$-dimensional arrays (called tensors). Let $k$ be a scalar, $\\mathbf{v}$ and $\\mathbf{w}$ be vectors, $A$ and $B$ be matrices, and $T$ be a tensor, such that\n",
    "$$k=7,\\quad \\mathbf{v} = \\begin{pmatrix} 2 \\\\ 2 \\\\ 1 \\\\ \\end{pmatrix}, \n",
    "\\quad \\mathbf{w} = \\begin{pmatrix} 13 \\\\ 20 \\\\ 10 \\\\ 21\\\\ \\end{pmatrix}, \\quad\n",
    "A = \\begin{bmatrix} 2 & 1 & 2 \\\\ 3 & 2 & 7 \\\\ 2 & 3 & 6 \\\\ \\end{bmatrix}, \\quad\n",
    "B = \\begin{bmatrix} 12 & 21 & 12 \\\\ 15 & 12 & 27 \\\\ 22 & 13 & 16 \\\\ \\end{bmatrix}, \\quad\n",
    "\\mathbf{T} = \n",
    "\\begin{bmatrix} \n",
    "\\begin{bmatrix} 2 & 1 & 2 \\\\ 3 & 2 & 7 \\\\ 2 & 3 & 6 \\\\ \\end{bmatrix} \\\\\n",
    "\\begin{bmatrix} 12 & 21 & 12 \\\\ 15 & 12 & 27 \\\\ 22 & 13 & 16 \\\\ \\end{bmatrix}\n",
    "\\end{bmatrix} = \\begin{bmatrix} A \\\\ B \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We can initialise PyTorch tensors to store this data in this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "976b488d-c367-413a-919a-b1ac78184655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalars\n",
    "scalar_k = torch.tensor(7)\n",
    "scalar_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ffe67b4-2f72-4712-8c8d-7fbb7e2b9bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 2, 1]), tensor([13, 20, 10, 12]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectors \n",
    "vector_v = torch.tensor([2,2,1])\n",
    "vector_w = torch.tensor([13,20,10,12])\n",
    "vector_v, vector_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8761de83-4f0d-476c-a064-8917afa68636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2, 1, 2],\n",
       "         [3, 2, 7],\n",
       "         [2, 3, 6]]),\n",
       " tensor([[12, 21, 12],\n",
       "         [15, 12, 27],\n",
       "         [22, 13, 16]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrices\n",
    "matrix_A = torch.tensor([\n",
    "    [2,1,2],\n",
    "    [3,2,7],\n",
    "    [2,3,6]\n",
    "])\n",
    "matrix_B = torch.tensor([\n",
    "    [12,21,12],\n",
    "    [15,12,27],\n",
    "    [22,13,16]\n",
    "])\n",
    "matrix_A, matrix_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14492a23-29f7-462b-9494-17a2e6dc1e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2,  1,  2],\n",
       "         [ 3,  2,  7],\n",
       "         [ 2,  3,  6]],\n",
       "\n",
       "        [[12, 21, 12],\n",
       "         [15, 12, 27],\n",
       "         [22, 13, 16]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensors (n-dimensional arrays)\n",
    "tensor_T = torch.tensor([\n",
    "    [\n",
    "       [2,1,2],\n",
    "        [3,2,7],\n",
    "        [2,3,6] \n",
    "    ],\n",
    "    [\n",
    "        [12,21,12],\n",
    "        [15,12,27],\n",
    "        [22,13,16]\n",
    "    ]\n",
    "])\n",
    "tensor_T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09113770-a5c1-42d7-a268-2ac52cfc0fe5",
   "metadata": {},
   "source": [
    "### Dimension and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb5289e7-5edb-4215-9016-75ffe66822c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a scalar has 0 dimension (dimensionless)\n",
    "scalar_k.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eab56f3b-02af-4d92-b063-ba4a8607372c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectors are one-dimensional\n",
    "vector_v.ndim, vector_w.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b47aa51e-0625-409a-9b7a-b4692c76d399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrices are two-dimensional\n",
    "matrix_A.ndim, matrix_B.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2631586b-f759-446b-9e8b-00e0aebaef7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensors are three-dimensional and up\n",
    "tensor_T.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a989db72-edf6-4c29-bfaa-2849e524a689",
   "metadata": {},
   "source": [
    "We now investigate the shape of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd07f3a6-3e85-470a-ba7e-fda75c5c41be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_k.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd82de4-a1db-4cfe-bfa7-e67549abfe8a",
   "metadata": {},
   "source": [
    "Scalars have no shape, what about vectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93dfbaff-7b85-478a-948f-ff35fbfab070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba4fa83-a7ab-4655-b99b-7fa7c53547fb",
   "metadata": {},
   "source": [
    "The shape of vectors say there are $n$ elements in the vector in question. For example, the shape of vector $\\mathbf{w}$ is $4$, it means $\\mathbf{w}$ has $4$ elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60c03f5f-0696-4d40-84dc-71e702a33b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3]), torch.Size([2, 3, 3]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_A.shape, tensor_T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c5ce72-3566-4efb-9170-9ddd39881b07",
   "metadata": {},
   "source": [
    "So in general, **the shape of a tensor describes the number of elements along each dimension**. For example, tensor $\\mathbf{T}$ has $2$ elements in the first dimension (the two matrices), and each matrix has $3$ columns (the second dimension), and each column has $3$ entries (third dimension)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc2528-09ec-4477-8d98-474ca4187eac",
   "metadata": {},
   "source": [
    "### Devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a809fe7-85cb-45fa-8be1-c88854597508",
   "metadata": {},
   "source": [
    "PyTorch can run on a CPU or on a GPU. We have to set the ```device``` to cuda if cuda-enabled GPU is available else it will default to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "378fc780-e45f-4088-a22d-3e24d026b409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e28b71-d55e-4f3c-b2fc-987d64e3a7d6",
   "metadata": {},
   "source": [
    "To initialize a new tensor on a device specified, we use the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a05f6434-fe40-42f6-969b-071361511174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor = torch.tensor([1,2,3], dtype=torch.float32, device=device)\n",
    "new_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471b3417-99ba-4698-beb6-17767891b39f",
   "metadata": {},
   "source": [
    "To move existing tensor to the device we use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c865261-9f21-46b8-83f2-20aa13cfc032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_T.to(device).device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf42a0-6460-4b61-ab0c-849219d04e4e",
   "metadata": {},
   "source": [
    "### NumPy and Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cb645d8-5158-43f7-9b5d-522867b0e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92f59d9d-1f50-4043-a972-20bc080b0fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.array([2,1,3])\n",
    "np_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3104d31f-a7fe-4369-a557-3268fcda5b2c",
   "metadata": {},
   "source": [
    "To create a tensor from NumPy ```ndarray```, we run the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ee4618c-93ae-4c78-8b96-6c4cdd995c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_from_numpy = torch.tensor(np_array)\n",
    "tensor_from_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b668b1f-0bc3-4636-b0a8-fdf2e6c43c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnsr_from_numpy = torch.from_numpy(np_array)\n",
    "tnsr_from_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a431da-5db6-4104-8c15-d30d6b8d7bb3",
   "metadata": {},
   "source": [
    "To convert a tensor into NumPy ```ndarray``` we use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7765e93-bddf-4d46-b889-7580f64d5b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_from_numpy.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b164881-9fbc-4afb-8235-6c193b7bedcc",
   "metadata": {},
   "source": [
    "To move from pandas dataframe to tensor and vice versa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf8f6b92-272b-4f0f-b4fc-88f715f4b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1.0, 2.0, 3.0],\n",
    "    'B': [4.0, 5.0, 6.0]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4494b24-2a3f-4316-933b-ab171fde2479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4.],\n",
       "        [2., 5.],\n",
       "        [3., 6.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from pandas to tensor\n",
    "torch.tensor(df.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65dd80fa-df02-4941-8b33-ea051a08d53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "0  2  1  2\n",
       "1  3  2  7\n",
       "2  2  3  6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensor to pandas\n",
    "pd.DataFrame(matrix_A.numpy(), columns=['A', 'B', 'C']) # specify the columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257905e2-3d0b-4d03-a1a6-deb25f3c7c9a",
   "metadata": {},
   "source": [
    "### Other common initialization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6be539c-25c3-4bc9-9cb6-e78e5af339ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.2505e+11,  9.3467e-43]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a tensor with an uninitialised entries (entries may be whatever is in the memory)\n",
    "torch.empty((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ba6e535-6c8d-4cf5-9123-c18681f8115f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a tensor with 0 entries\n",
    "torch.empty((3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7970f555-f2e3-4568-9ad3-ba6481c11da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a tensor with 1 entries\n",
    "torch.ones((2,2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdd7af4c-450a-4b2e-8705-07c00f7a0174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3435], dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a random tensor\n",
    "torch.rand(1, dtype=torch.float64, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e379769-92da-4dda-88f2-6f4099c64503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1]], dtype=torch.int8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates an identity matrix\n",
    "torch.eye(7, dtype=torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1516ee0e-f051-4463-a6d7-a4879f37dc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.0000, 18.8889, 27.7778, 36.6667, 45.5556, 54.4444, 63.3333, 72.2222,\n",
       "        81.1111, 90.0000])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# starts at 'start', ends at 'end', and makes sure there are 'steps'/values between 'start' and 'end'\n",
    "torch.linspace(start=10, end=90, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8707289-92e1-4fb1-884c-9016cd87fd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 12, 14, 16, 18, 20])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# works similarly to python's arange function\n",
    "torch.arange(start=10, end=22, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1255c348-e9fb-4aab-abb6-7d2b55c1ac3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 12, 14, 16, 18, 20]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10,22,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97231c04-335e-4ad7-a920-0d5745e2433a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2447,  0.7794, -0.0952, -0.5203, -0.3524, -1.8581, -0.2164,  0.2737,\n",
       "          0.4727,  0.1196]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fills self tensor with elements samples from the normal distribution parameterized by mean and std\n",
    "torch.empty(size=(1,10)).normal_(mean=0, std=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60232141-c915-45d3-ac3e-656ea269e1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14.8226, 12.0745, 12.6554, 14.4834, 14.5791, 14.6777, 14.9227, 13.0805,\n",
       "         14.9706, 13.4336, 13.6891, 14.9503, 14.5773, 14.6093, 13.4869, 14.9141,\n",
       "         14.2065, 12.4368, 14.0307, 12.9429, 12.2360, 13.9300, 13.5394, 12.5432,\n",
       "         14.5043, 14.0182, 14.2424, 12.2127, 14.2983, 14.2305, 14.7003, 12.4082,\n",
       "         13.6703, 13.1115, 12.9725, 14.1429, 14.6416, 12.1552, 14.5767, 12.4684,\n",
       "         12.4718, 13.1372, 12.0812, 13.7628, 14.1279, 14.7925, 13.1097, 14.5880,\n",
       "         14.2641, 13.1057, 12.2301, 14.6504, 14.1189, 12.4299, 14.6281, 14.1733,\n",
       "         14.7446, 13.1821, 12.9533, 14.5342, 13.3801, 14.0148, 12.0348, 13.2964,\n",
       "         14.8919, 13.0803, 13.9430, 12.4567, 12.0293, 14.3399, 13.9862, 14.3409,\n",
       "         13.4746, 14.3799, 13.1609, 13.8925, 13.0767, 13.0064, 12.1014, 13.2868,\n",
       "         12.4728, 12.1787, 14.9755, 12.6716, 13.9604, 14.4200, 14.5912, 12.7536,\n",
       "         14.9629, 13.0740, 14.9758, 12.3238, 12.9955, 14.0515, 13.3790, 12.1428,\n",
       "         14.9291, 14.3067, 12.6439, 12.0420]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(size=(1,100)).uniform_(12, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff45f7f-deec-4d64-a815-d3ba771ffd88",
   "metadata": {},
   "source": [
    "**Tensor Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa0cf745-a86c-4196-bfab-f782893ee9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.ones(size=(1,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ea773824-ba8c-458e-837f-2afb518f9e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.bool()\n",
    "tensor.short() # int16\n",
    "tensor.long() # int64\n",
    "tensor.float() # float32\n",
    "tensor.half() # float16\n",
    "tensor.double() # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e212f4-428e-47ca-b735-3df122169790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf24a0d-31a2-4553-ad06-36dd233c931e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685e66f9-d797-4ab7-a4f6-bbc9ca60cdb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9114b9a4-a661-4df4-844f-40514ebbc163",
   "metadata": {},
   "source": [
    "## 2. Tensor Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98f11ae6-2df5-45ad-a207-c2532aa17208",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_X=torch.tensor([1,2,3])\n",
    "tensor_Y = torch.tensor([2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9215bc6f-5cdc-4f84-8304-b3715984252e",
   "metadata": {},
   "source": [
    "**Addition**\n",
    "\n",
    "Let $Z$ be $$Z=X+Y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bdf0d762-398e-4fd6-a7b8-8090bbcc568a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 4.4766e+00, 3.6013e-43]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_Z = torch.empty((1,3))\n",
    "tensor_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f6ee61b-754a-42a2-936f-f7ee50162823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 5., 7.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor_X, tensor_Y, out=tensor_Z.resize_(0))\n",
    "tensor_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb7cb067-32d1-4b72-a1ee-80e406dd55d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 5, 7])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_Z = torch.add(tensor_X, tensor_Y)\n",
    "tensor_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "58e00b75-2c89-4fb8-9b1e-19858eb699a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 5, 7])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_Z = tensor_X.add(tensor_Y)\n",
    "tensor_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e040a9ec-1277-40f4-b8cf-e5034f79875a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 5, 7])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_Z = tensor_X + tensor_Y\n",
    "tensor_Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423d690a-d534-4cda-9c46-10faafb15471",
   "metadata": {},
   "source": [
    "**Subtraction**\n",
    "\n",
    "Let $Z$ now be $$Z=X-Y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "db3c9fbb-4cf0-4952-88ab-399ee1daa31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1, -1, -1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_Z = tensor_X-tensor_Y\n",
    "tensor_Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a44a425-9a3f-464b-a8a9-f0dd02544b28",
   "metadata": {},
   "source": [
    "**Division**\n",
    "\n",
    "Let $k$ be a scalar and $Z$ be a tensor vector\n",
    "\n",
    "$$k=2, \\qquad Z = X \\otimes Y, \\qquad \\text{ where } \\otimes \\text{ represents element-wise division operation }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "119fa2fb-6aeb-4063-ad8b-4af3ce15569b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_k = torch.tensor(2)\n",
    "scalar_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c7a10067-9da4-4104-81e9-0a4ef9fccc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 0.6667, 0.7500])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor-tensor division\n",
    "tensor_Z = torch.true_divide(tensor_X, tensor_Y)\n",
    "tensor_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8052505b-1c5d-4d63-af1a-86d93c2013f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 1.0000, 1.5000])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar divistion\n",
    "torch.true_divide(tensor_X, scalar_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aa1300-e5f6-48cf-8f46-4128ab5d7cd2",
   "metadata": {},
   "source": [
    "**Inplace operations**\n",
    "\n",
    "Inplace operations are when duplicate copies are not created during the operations. For large datasets, this can be helpful to save computation resources, but it comes it a downside. The following are inplace operations. In general, every function with an underscore suffix, is an inplace operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f78ac0ab-9c30-48cf-996c-0ee9ba521295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 5, 7])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_X.add_(tensor_Y) # inplace operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "74c41566-3acc-486e-85f1-463532fbfe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_Y += tensor_Y + 1 # inplace operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fcd14cf8-302d-4515-a235-c2485cd66095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 7, 9])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d93b5677-e503-427a-9e97-3df7d14e50b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 12, 16])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_X = tensor_X + tensor_Y # not an inplace operation (a copy is created during operation)\n",
    "tensor_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572a28b4-52f7-47a0-9441-101e2fc87b00",
   "metadata": {},
   "source": [
    "**Exponentiation and element-wise comparison**\n",
    "\n",
    "Exponentiation is similar to standard python exponentiation, and functions are the same. Element-wise operations are similar to that of numpy and pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a006c18e-7b95-4a4a-bf05-197175392272",
   "metadata": {},
   "source": [
    "**Matrix Multiplication and Exponentiation**\n",
    "\n",
    "Let $A$ and $B$ be matrices:\n",
    "$$\n",
    "A = \\begin{bmatrix} 2 & 1 & 2 \\\\ 3 & 2 & 7 \\\\ 2 & 3 & 6 \\\\ \\end{bmatrix}, \\quad\n",
    "B = \\begin{bmatrix} 12 & 21 & 12 \\\\ 15 & 12 & 27 \\\\ 22 & 13 & 16 \\\\ \\end{bmatrix}, \\quad\n",
    "$$\n",
    "We want to compute $A^5$ and $AB$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7b4c330b-96d4-4d53-9689-ff1d82f9c419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9428,  9760, 22484],\n",
       "        [25328, 26224, 60416],\n",
       "        [24460, 25328, 58348]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_A.matrix_power(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "36766c5d-2117-47c8-a8ca-dfaa4092795c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 83,  80,  83],\n",
       "        [220, 178, 202],\n",
       "        [201, 156, 201]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AB = torch.mm(matrix_A, matrix_B)\n",
    "AB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd8a779-b37b-43c6-993b-80653a9e474e",
   "metadata": {},
   "source": [
    "**Element-wise multiplication and the dot-product**\n",
    "Suppose $\\mathbf{w}$ and $\\mathbf{v}$ are vectors as follows \n",
    "$$\\mathbf{v} = \\begin{pmatrix} 2 \\\\ 2 \\\\ 1 \\\\ \\end{pmatrix}, \n",
    "\\quad \\mathbf{w} = \\begin{pmatrix} 13 \\\\ 20 \\\\ 10 \\\\ \\end{pmatrix}$$\n",
    "We want to compute $\\mathbf{w}\\bullet \\mathbf{v}$ and $\\mathbf{w}\\otimes \\mathbf{v}$ where $\\otimes$ is element-wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "95212158-72dc-4ecc-89db-44c35be5e816",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_w = torch.tensor((13,20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4eca6140-9572-44ec-84b4-128e8c5bdb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(76)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(vector_w, vector_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "95b564c8-041e-4c1f-9890-f4a8e339fb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([26, 40, 10])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_w * vector_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528414fb-05ac-41f9-9e5a-4e79e72aad24",
   "metadata": {},
   "source": [
    "**Batch matrix multiplication**\n",
    "\n",
    "Suppose we have tensors $\\mathbf{A}\\in\\mathbb{R}^{b\\times n \\times m}$ and $\\mathbf{B}\\in\\mathbb{R}^{b\\times m \\times p}$\n",
    "\n",
    "We want to compute $\\mathbf{AB}$. (**TODO:** Investigate this more) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7fc9e823-0d8a-47e1-9c82-386e84e10f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose we have\n",
    "batch=32\n",
    "n=10\n",
    "m=20\n",
    "p=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3155cc43-4b91-4be6-a1e5-18db7027dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_A = torch.rand((batch, n, m))\n",
    "T_B = torch.rand((batch, m, p))\n",
    "T_AB = torch.bmm(T_A, T_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac5366c-f025-4eb7-a773-af4c021b8965",
   "metadata": {},
   "source": [
    "**Broadcasting**\n",
    "\n",
    "If we have matrix $A$ and vector $\\mathbf{w}$, mathematically, it doesn't make sense to compute \n",
    "$A+\\mathbf{w}$, but with PyTorch, it's possible, since $\\mathbf{w}$ is _broadcasted_ to match $A$'s dimensions. So in PyTorch, $A+\\mathbf{w}$ becomes\n",
    "\n",
    "$$A+\\mathbf{w} = \n",
    "\\begin{bmatrix} 2 & 1 & 2 \\\\ 3 & 2 & 7 \\\\ 2 & 3 & 6 \\\\ \\end{bmatrix} + \n",
    "\\begin{pmatrix} 13 \\\\ 20 \\\\ 10 \\\\ \\end{pmatrix} = \n",
    "\\begin{bmatrix} 2 & 1 & 2 \\\\ 3 & 2 & 7 \\\\ 2 & 3 & 6 \\\\ \\end{bmatrix} + \n",
    "\\begin{pmatrix} 13 & 13 & 13 \\\\ 20 & 20 & 20 \\\\ 10 & 10 & 10 \\\\ \\end{pmatrix}\n",
    "= \\begin{bmatrix} 15 & 14 & 15 \\\\ 23 & 22 & 27 \\\\ 12 & 13 & 16 \\\\ \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dcc3514a-63ac-49d7-a527-192af7c6219a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15, 21, 12],\n",
       "        [16, 22, 17],\n",
       "        [15, 23, 16]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_A + vector_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b2ce1b-ea51-4a9c-ae6e-2355cfd31b2a",
   "metadata": {},
   "source": [
    "**Other commonly used mathematical operations**\n",
    "- ```torch.sum(...)```\n",
    "- ```torch.max(...)```, ```torch.min(...)```\n",
    "- ```torch.abs(...)```\n",
    "- ```torch.argmax(...)```, ```torch.argmin(...)```\n",
    "- ```torch.mean(...)```\n",
    "- ```torch.median(...)```\n",
    "- ```torch.eq(...)```, equality\n",
    "- ```torch.sort(...)```\n",
    "- ```torch.clamp(...)``` , see documentation and examples\n",
    "- ```torch.any(...)```\n",
    "- ```torch.all(...)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0d1bf1-b194-4065-8ca9-40ccf3eebd05",
   "metadata": {},
   "source": [
    "## 3. Tensor Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f01d38c-46a2-4857-b99f-82c9b81f7d49",
   "metadata": {},
   "source": [
    "Tensor indexing works as follows:\n",
    "\n",
    "```python\n",
    "tensor[n_1, n_2, n_3, ...]\n",
    "```\n",
    "\n",
    "- $n_1$: Refers to the specific index(es) desired in the **first dimension**.\n",
    "- $n_2$: Refers to the specific index(es) desired in the **second dimension**.\n",
    "- $n_3$: Refers to the specific index(es) desired in the **third dimension**, and so on.\n",
    "\n",
    "For example, consiser a matrix $A$,\n",
    "$$\\begin{bmatrix} 2 & 1 & 2 \\\\ 3 & 2 & 7 \\\\ 2 & 3 & 6 \\\\ \\end{bmatrix}$$\n",
    "which has the shape ```(rows, columns)``` -> ```(3, 3)```. If you run \n",
    "```python\n",
    "matrix_A[2,1]\n",
    "```\n",
    "You are saying, I want row **3**  and column **2** which will be $3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b0169431-8351-4c5d-89d5-3f6a5975259e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_A[2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "63dc36b0-0cac-492c-a2fe-84965ccafe1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_A[(0,2), [2,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c24eb4e-99c9-4eaa-b3cb-4d5c0a41b896",
   "metadata": {},
   "source": [
    "Get all the elements less than or equals to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "76d41187-9ae0-4771-a977-be38d6cbd33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 2, 3, 2, 2, 3])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_bounded=matrix_A[matrix_A<=3]\n",
    "three_bounded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ab32f9-4e1a-410a-b5a6-21494fc1cf5f",
   "metadata": {},
   "source": [
    "Get unique elements from a matrix/tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "18098350-92ae-40d2-9380-66bd709bef5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_bounded.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f00f31-232e-4efc-a4a1-319796715d2a",
   "metadata": {},
   "source": [
    "Using the ```torch.where(...)``` function\n",
    "\n",
    "```python\n",
    "torch.where(condition, statement_if_true, statement_if_false)\n",
    "```\n",
    "Similar Exel's WHERE function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e9492646-401d-4920-a55f-5ff065f601f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.0000, 3.0000, 6.0000],\n",
       "        [9.0000, 6.0000, 2.3333],\n",
       "        [6.0000, 9.0000, 2.0000]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if element is greater than 3, divide it by 3, else multiply it by 2\n",
    "torch.where(matrix_A > 3, matrix_A / 3, matrix_A * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9ee40213-8d55-4bb2-a6e9-7a3a9c08c17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of elements in the tensor\n",
    "matrix_A.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c72497a-f66f-4741-8e7a-6ad863c40991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1edc5e40-36b9-4044-b711-05920d8a71c2",
   "metadata": {},
   "source": [
    "## 4. Tensor Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad29ecc3-0148-4bb8-bb6a-5430115ea695",
   "metadata": {},
   "source": [
    "Reshaping and related operations in PyTorch are essential when working with tensors, as they allow you to adjust the structure of data without altering its content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752a5bdd-5127-4fba-8377-ab7acd572e4b",
   "metadata": {},
   "source": [
    "**Reshaping: `reshape` and `view`**\n",
    "\n",
    " **`reshape`**\n",
    "- Allows you to change the shape of a tensor while maintaining its data.\n",
    "- The new shape must have the same total number of elements as the original tensor.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "import torch\n",
    "a = torch.arange(12)  # Tensor with 12 elements [0, 1, ..., 11]\n",
    "reshaped = a.reshape(3, 4)  # Reshape to 3x4 matrix\n",
    "print(reshaped)\n",
    "```\n",
    "\n",
    "**`view`**\n",
    "- Similar to `reshape`, but operates differently under the hood.\n",
    "- It returns a tensor with the same data but interpreted with a new shape (requires the tensor to be contiguous in memory).\n",
    "\n",
    "Example:\n",
    "```python\n",
    "viewed = a.view(3, 4)  # View as 3x4 matrix\n",
    "print(viewed)\n",
    "```\n",
    "\n",
    "**Note**: Use `view` only if you’re sure the tensor is contiguous; otherwise, `reshape` is safer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c172b55-d689-4905-99fc-aa454ad93d39",
   "metadata": {},
   "source": [
    "**Stacking: `stack` and `cat`**\n",
    "\n",
    "#### **`stack`**\n",
    "- Combines multiple tensors along a new dimension.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "stacked = torch.stack([a, b], dim=0)  # Add a new dimension (0)\n",
    "print(stacked)  # [[1, 2, 3], [4, 5, 6]]\n",
    "```\n",
    "\n",
    "**`cat`**\n",
    "- Concatenates tensors along an existing dimension.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "concatenated = torch.cat([a.unsqueeze(0), b.unsqueeze(0)], dim=0)\n",
    "print(concatenated)  # [[1, 2, 3], [4, 5, 6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1fcf5b-95d4-4cba-b216-55686a69bc0a",
   "metadata": {},
   "source": [
    "**Adding and Removing Dimensions: `squeeze` and `unsqueeze`**\n",
    "\n",
    "**`unsqueeze`**\n",
    "- Adds a new dimension of size 1 at the specified position.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "a = torch.tensor([1, 2, 3])\n",
    "unsqueezed = a.unsqueeze(0)  # Add a dimension at 0 (row vector)\n",
    "print(unsqueezed)  # [[1, 2, 3]]\n",
    "```\n",
    " **`squeeze`**\n",
    "- Removes dimensions of size 1.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "b = torch.tensor([[1, 2, 3]])  # Shape [1, 3]\n",
    "squeezed = b.squeeze(0)  # Remove the 0th dimension\n",
    "print(squeezed)  # [1, 2, 3]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e909a62-b01c-47a1-aa26-d7f287404720",
   "metadata": {},
   "source": [
    "**Transposing: `transpose` and `permute`**\n",
    "\n",
    "**`transpose`**\n",
    "- Swaps two specified dimensions of a tensor.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])  # Shape [2, 3]\n",
    "transposed = a.transpose(0, 1)  # Swap dimensions 0 and 1\n",
    "print(transposed)  # [[1, 4], [2, 5], [3, 6]]\n",
    "```\n",
    "**`permute`**\n",
    "- Allows reordering of all dimensions.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "a = torch.randn(2, 3, 4)  # Shape [2, 3, 4]\n",
    "permuted = a.permute(2, 0, 1)  # Change to [4, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54db47-d19a-425e-a4a5-3b9ff1e6c266",
   "metadata": {},
   "source": [
    "**Flattening: `flatten`**\n",
    "\n",
    "- Collapses specified dimensions into one.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "flattened = a.flatten()  # Flattens to [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f2c67d-cb15-4530-a9b6-a0c884f7f165",
   "metadata": {},
   "source": [
    " **Splitting: `chunk` and `split`**\n",
    "\n",
    " **`chunk`**\n",
    "- Splits a tensor into equal-sized chunks along a specified dimension.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "a = torch.arange(10)  # [0, 1, ..., 9]\n",
    "chunks = torch.chunk(a, 5)  # Split into 5 chunks\n",
    "print(chunks)\n",
    "```\n",
    "\n",
    "**`split`**\n",
    "- Splits a tensor into chunks of specified sizes.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "splits = torch.split(a, [3, 7])  # Split into chunks of sizes 3 and 7\n",
    "print(splits)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e656cf-e8f3-4f40-a284-1e77cdf029a6",
   "metadata": {},
   "source": [
    "**Expanding and Repeating: `expand` and `repeat`**\n",
    "\n",
    "**`expand`**\n",
    "- Expands a tensor along singleton dimensions (without copying data).\n",
    "\n",
    "Example:\n",
    "```python\n",
    "a = torch.tensor([1, 2, 3]).unsqueeze(0)  # [1, 3]\n",
    "expanded = a.expand(3, 3)  # Expand to [3, 3]\n",
    "```\n",
    "\n",
    "**`repeat`**\n",
    "- Repeats elements of a tensor (copies data).\n",
    "\n",
    "Example:\n",
    "```python\n",
    "repeated = a.repeat(3, 1)  # Repeat along specified dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476ce6af-afaa-4574-b2fe-61f52f4f54f2",
   "metadata": {},
   "source": [
    "### When to Use Which Function:\n",
    "1. **`reshape`**: To change the shape of data.\n",
    "2. **`stack`/`cat`**: To combine tensors.\n",
    "3. **`squeeze`/`unsqueeze`**: To adjust dimensions.\n",
    "4. **`transpose`/`permute`**: To reorder dimensions.\n",
    "5. **`split`/`chunk`**: To divide tensors.\n",
    "6. **`expand`/`repeat`**: For broadcasting-like behaviors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661eff11-7d91-4840-a97c-67bae1017b49",
   "metadata": {},
   "source": [
    "## 5. Common mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb4768-919b-465c-8426-0e724d4146d1",
   "metadata": {},
   "source": [
    "Head over to [learnpytorch.io](https://www.learnpytorch.io/pytorch_most_common_errors/)'s tutorial on this one\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
